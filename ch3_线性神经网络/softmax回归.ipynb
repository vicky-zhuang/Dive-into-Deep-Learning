{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax回归从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size,resize=None):\n",
    "    '''下载Fashion-MNIST数据集，然后将其加载到内存中'''\n",
    "    trans = [transforms.ToTensor()] #将原始的PILImage格式或者numpy.array格式的数据格式化为可被pytorch快速处理的张量类型。\n",
    "    if resize:\n",
    "        trans.insert(0,transforms.Resize(resize)) # 调整PILImage对象的尺寸\n",
    "    trans = transforms.Compose(trans) # 把多个步骤整合在一起\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root='./',train=True,transform=trans,download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root='./',train=False,transform=trans,download=True)\n",
    "    mnist_train_loader = data.DataLoader(mnist_train,batch_size,shuffle=True,num_workers=4)\n",
    "    mnist_test_loader = data.DataLoader(mnist_test,batch_size,shuffle=False,num_workers=4)\n",
    "    return mnist_train_loader,mnist_test_loader\n",
    "\n",
    "\n",
    "def get_fashion_minist_labels(labels):\n",
    "    text_labels = ['t-shirt','trouser','pullover','dress','coat',\n",
    "                   'sandal','shirt','sneaker','bag','ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter,test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_iter:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0,0.01,size=(num_inputs,num_outputs),requires_grad=True) # [784,10]\n",
    "b = torch.zeros(num_outputs,requires_grad=True) # [1,10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、定义softmax操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    x_exp = torch.exp(X)\n",
    "    return x_exp/x_exp.sum(dim=1,keepdim=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape(-1,W.shape[0]),W)+b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat,y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)),y]) # 使用y当作列的索引取到正确类的概率，然后直接取对数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、分类精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    '''计算准确预测的样本数'''\n",
    "    y_hat = y_hat.argmax(dim=1)\n",
    "    cmp = y_hat.type(y.dtype)==y\n",
    "    return float(cmp.type(y.dtype).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat,y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    '''在n个变量上进行累加'''\n",
    "    def __init__(self,n):\n",
    "        self.data = [0.0]*n\n",
    "    \n",
    "    def add(self,*args):\n",
    "        self.data =[a+float(b) for a,b in zip(self.data,args)]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.data = [0.0]*len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net,data_iter):\n",
    "    '''在指定的数据集上评估模型的精度'''\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        net.eval() # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for x,y in data_iter:\n",
    "            metric.add(accuracy(net(x),y),y.numel())\n",
    "    return metric[0]/metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1248"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(net,test_iter) # 因为这里一共10个类，随机初始化的参数准确率大约在10%左右"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad / batch_size\n",
    "            param.grad.zero_()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,data_iter,loss_fn,lr):\n",
    "    '''训练模型一个周期'''\n",
    "    metric = Accumulator(3) # 训练损失总和、训练准确度总和、样本数\n",
    "    for x,y in data_iter:\n",
    "        y_hat = net(x) # 前向传播\n",
    "        l = loss_fn(y_hat,y) # 计算损失\n",
    "        l.sum().backward() # 后向传播\n",
    "        sgd([W,b],lr,batch_size) # 更新参数，参数梯度归零\n",
    "        metric.add(float(l.sum()),accuracy(y_hat,y),y.numel())\n",
    "    return metric[0]/metric[2],metric[1]/metric[2] # 单个样本平均训练损失，准确率\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_iter,test_iter,loss_fn,lr,num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss,train_acc = train_epoch(net,train_iter,loss_fn,lr)\n",
    "        test_acc = evaluate_accuracy(net,test_iter)\n",
    "        print(epoch+1,train_loss,train_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.033520164489746 0.6965666666666667 0.7454\n",
      "2 0.7084728014628092 0.7767 0.7757\n",
      "3 0.636662836265564 0.79825 0.791\n",
      "4 0.5972671895345052 0.8091666666666667 0.8011\n",
      "5 0.5714250760396321 0.8168833333333333 0.8051\n",
      "6 0.5528819741566976 0.8205333333333333 0.8106\n",
      "7 0.5385389862696329 0.82455 0.8137\n",
      "8 0.5271430640538534 0.8272666666666667 0.8171\n",
      "9 0.5173635903040568 0.8296333333333333 0.8188\n",
      "10 0.5094965869903565 0.8321 0.8203\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "lr = 0.03\n",
    "train(net,train_iter,test_iter,cross_entropy,lr,num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgs,num_rows,num_cols,titles,scale=1.5):\n",
    "    _,axes = plt.subplots(num_rows,num_cols,figsize=(num_cols*scale,num_rows*scale))\n",
    "    axes = axes.flatten() # 把二维的numpy.ndarray拉成一维\n",
    "    for i,(ax,img) in enumerate(zip(axes,imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            ax.imshow(img.numpy()) # 图片张量\n",
    "        else:\n",
    "            ax.imshow(img) # PIL图片\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net, test_iter, n=6):\n",
    "    for x,y in test_iter:\n",
    "        break\n",
    "    trues = get_fashion_minist_labels(y)\n",
    "    preds = get_fashion_minist_labels(net(x).argmax(1))\n",
    "    titles = [true+'\\n'+pred for true,pred in zip(trues,preds)]\n",
    "    show_images(x[0:n].reshape(n,28,28),1,n,titles[0:n])\n",
    "\n",
    "\n",
    "predict(net, test_iter, n=6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## softmax回归的简洁实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "batch_size = 256\n",
    "train_iter,test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Flatten(),nn.Linear(784,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.normal_(m.weight,std=0.01)\n",
    "\n",
    "net.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,train_iter,loss,trainer):\n",
    "    metric = Accumulator(3)\n",
    "    for x,y in train_iter:\n",
    "        y_hat = net(x)\n",
    "        l = loss(y_hat,y)\n",
    "        trainer.zero_grad()\n",
    "        l.mean().backward()\n",
    "        trainer.step()\n",
    "        metric.add(float(l.sum()),accuracy(y_hat,y),y.numel())\n",
    "    return metric[0]/metric[2],metric[1]/metric[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_iter,test_iter,loss,trainer,num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss,train_acc = train_epoch(net,train_iter,loss,trainer)\n",
    "        test_acc = evaluate_accuracy(net,test_iter)\n",
    "        print(epoch+1,train_loss,train_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7865897769927979 0.7478666666666667 0.7852\n",
      "2 0.5703130973815917 0.8132166666666667 0.8074\n",
      "3 0.5249946798960368 0.8270833333333333 0.8172\n",
      "4 0.5008768747965495 0.8326666666666667 0.8143\n",
      "5 0.48550347595214843 0.8359833333333333 0.791\n",
      "6 0.47450652389526365 0.8402666666666667 0.8269\n",
      "7 0.46455805123647054 0.8426833333333333 0.8292\n",
      "8 0.45832816429138185 0.8442 0.8291\n",
      "9 0.45243869819641114 0.8467166666666667 0.8321\n",
      "10 0.4478655403137207 0.8482833333333333 0.833\n",
      "11 0.4424949731826782 0.8490166666666666 0.8356\n",
      "12 0.4396551072438558 0.85 0.8322\n",
      "13 0.4356987876256307 0.85185 0.8368\n",
      "14 0.4329678873697917 0.8513333333333334 0.8361\n",
      "15 0.4309636246363322 0.8526333333333334 0.8338\n",
      "16 0.4272518388748169 0.8542666666666666 0.8302\n",
      "17 0.42634141572316486 0.8542 0.8292\n",
      "18 0.42420314067204795 0.8550666666666666 0.8366\n",
      "19 0.4224140298207601 0.8544666666666667 0.8355\n",
      "20 0.4202173875172933 0.8565666666666667 0.8371\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "train(net,train_iter,test_iter,loss,trainer,num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
